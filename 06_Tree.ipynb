{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be76705a-4559-46f8-8f23-236a43fcd966",
   "metadata": {},
   "source": [
    "# Decision Tree #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d039282-b4a2-40b5-8448-e7fa821d4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import matplotlib\n",
    "\n",
    "print('python:',sys.version)\n",
    "print('Numpy:',np.__version__)\n",
    "print('Pandas:',pd.__version__)\n",
    "print('Scikitlearn:',sklearn.__version__)\n",
    "print('Seaborn: ',sns.__version__)\n",
    "print('matplotlib:',matplotlib.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc726c-afb9-4bd4-b484-5ebbaae38ddd",
   "metadata": {},
   "source": [
    "Decision Tree:\n",
    "<ul>\n",
    "<li>Supervised Learning </li>\n",
    "<li>Works for both classification and regression </li>\n",
    "<li>Foundation of random Forests</li>\n",
    "<li>Attractive because of interpretability</li>\n",
    "</ul>\n",
    "Decision Tree works by:\n",
    "<ul>\n",
    "<li>Split based on set impurity criteria </li>\n",
    "<li>Stopping criteria </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d38c2-cde5-444b-b88a-6e92221a4da6",
   "metadata": {},
   "source": [
    "Some advantages of decision trees are:\n",
    "<ul>\n",
    "<li> Simple to understand and to interpret. Trees can be visualised.</li>  \n",
    "<li> Requires little data preparation. </li>\n",
    "<li>Able to hundle both numerical and categorical data. </li>\n",
    "<li>Possible to validate a model using statistical tests. </li>\n",
    "<li>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated. </li>\n",
    "</ul>\n",
    "The disadvantages of decision trees include:\n",
    "<ul>\n",
    "<li>Overfitting.Mechanisms such as pruning (not currently supported), setting the minimum number of samples required at a leaf node or sitting the maximum depth of the tree are necessary to avoid this problem.</li>\n",
    "<li>Decision trees can be unstable. Mitigant: use decision trees within an ensemble.</li>\n",
    "<li>Cannot guarantee to return the globally optimal decision tree. Mitigant: Training multiple trees in an ensemble learner.</li>\n",
    "<li>Decision tree learners create biased trees if some classes dominate. Recommendation: balance the dataset prior to fitting.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c5bac-6092-47bf-b825-590e2dd08421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "X=[[0,0],[1,2]]\n",
    "Y=[0,1]\n",
    "clf=tree.DecisionTreeClassifier()\n",
    "clf=clf.fit(X,Y)\n",
    "clf.predict([[2,2]])\n",
    "clf.predict_proba([[2,2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd04237-b0b0-49d7-9745-5e4f61627471",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[0.4, 1.2]])\n",
    "clf.predict_proba([[0.4, 1.2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9cdef-d63b-4172-b721-601e96979ba7",
   "metadata": {},
   "source": [
    "### The Iris Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1036b-6c93-4660-8798-7c2268cbcae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "Iris=pd.read_csv(r'C:\\Users\\minam\\Dev py\\Coursera\\Machine Learning_Anthony Ng/Data/Iris.csv')\n",
    "Iris\n",
    "col=['PetalLengthCm','PetalWidthCm','Species']\n",
    "X=Iris.iloc[:,1:5]\n",
    "Y=Iris['Species'].map({'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2})\n",
    "X , Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61da121-0a70-44ff-8e45-841788f02fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=tree.DecisionTreeClassifier(random_state=42)\n",
    "X_=X.iloc[:,2:5]\n",
    "clf=T.fit(X_.values,Y)\n",
    "clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f9a83-e7f0-4ee7-a86d-06de35597ad0",
   "metadata": {},
   "source": [
    "# I. Graphviz #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e63a3-42dc-4bb4-84e7-ee76aa4e7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "#tn=np.unique(Iris['Species'])#,return_counts=True)\n",
    "export_graphviz(cl_, out_file='mytree.dot',class_names=True,rounded=True, filled=True )\n",
    "#command prompt: dot -Tpng mytree.dot -o tree.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3b35d-9c73-475c-8b55-fcbf5e1ae8eb",
   "metadata": {},
   "source": [
    " <img src=\"tree.png\" alt=\"TreeClassifierGraphviz\" width=\"1000\" height=\"800\"> \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f00030-2bca-4bd5-8c65-4c0141c37e90",
   "metadata": {},
   "source": [
    "### 2nd method: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1e0cb-bbf1-460d-9ca9-ec2c6637bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data=tree.export_graphviz(cl_, out_file=None,class_names=True,rounded=True, filled=True )\n",
    "graph=graphviz.Source(dot_data)\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc445ea-d35b-4bd2-a283-a1cb86e3c39c",
   "metadata": {},
   "source": [
    "# II. Visualise the decision Boundary #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9307a-669a-48fd-b5c6-4d709d2486f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv=X_.values.reshape(-1,1)\n",
    "h=0.02\n",
    "X_min,X_max=Xv.min(),Xv.max()+1\n",
    "Y_min,Y_max=Y.min(),Y.max()+1\n",
    "xx,yy=np.meshgrid(np.arange(X_min,X_max,h), np.arange(Y_min,Y_max,h))\n",
    "xx.shape , yy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b3b2d-85a7-46c4-be87-1b811b2eb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z=z.reshape(xx.shape)\n",
    "fig=plt.figure(figsize=(10,6))\n",
    "ax=plt.contourf(xx, yy,z,cmap='afmhot',alpha=0.3)\n",
    "plt.scatter(X_.values[:,0], X_.values[:,1],c=Y, s=80,alpha=0.9, edgecolors='g')\n",
    "plt.show()\n",
    "##ValueError: X has 2 features, but DecisionTreeClassifier is expecting 4 features as input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297b621-305c-475c-ae43-51881a3c37dc",
   "metadata": {},
   "source": [
    "### Tree algorithms: ID3, C4.5, C5.0 and CART ###\n",
    "<ul>\n",
    "<li><b>ID3: </b> Iterative Dicotomiser3 developped in 1986 by Ross Quinlan. The algorithm creates a multiway tree finding for each other(in a greedy manner for example) the categorical feature that will yield the largest information gain for categorical targets. Trees are grown to their maximum size and then a pruning step is usually applied to improve the ability of the tree to generalise to unseen data.</li>\n",
    "<li><b>C4.5 : </b>is the successor of ID3, and removed the restriction that features must be categorical by dynamically defining a discrete attribute (based on numerical variables) that partitions the continuous attribute value into a discrete set of intervals. C4.5 converts the training trees (example the output of ID3 algorithm) into sets of if-then  rules. The accuracy of each rule is then evaluated to determine the order in which they should be applied.\n",
    "Pruning is done by remoing a rule's precondition if the accuracy of the rule improves without it.</li>\n",
    "<li><b>C5.0 : </b>is Quinlan's latest version release under proprietary license.It uses less memory and builds smaller rulesets that C4.5, while being more accurate. </li>\n",
    "<li><b>CART : </b>(Classification and Regression Trees) is very similar to C4.5, but differs in that it supports numerical target variables(regression) and does not compute rule sets.\n",
    "CART construct binary trees using the feature and threshold that yield the largest information gain at each node.\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b167c-a0d5-4c1b-9a28-3e1473aadf1f",
   "metadata": {},
   "source": [
    "### Gini impurity ###\n",
    "\n",
    "A measure of impurity/variability of categorical data. <br>\n",
    "Gini impurity and Gini coefficient:\n",
    "<ul>\n",
    "<li>Despite their names, they're not equivalent or even similar.</li>\n",
    "<li>G impurity is a measure of misclassification, which applies in a multiclass classifier context.</li>\n",
    "<li>G coefficient applies to binary classification and requires a classifier that can in some way rank examples according to the likelihood of being in a positive class.</li>\n",
    "<li>Both can be applied in some cases, but they are different measures for different things. Impurity is what is commonly used in decision trees.</li>\n",
    "</ul>\n",
    "Developped by Corrado GINI in 1912. <br>\n",
    "Key points:\n",
    "<ul>\n",
    "<li>A pure node (homogeneous contents or samples with same class) will have a gini coefficient of 0.</li>\n",
    "<li>As the variation increases (heterogeneous classes or increase diversity ), Gini coefficient increases and approaches 1 .</li>\n",
    "$$ Gini=1- \\sum _j ^r p_j^2 $$\n",
    "    p is the probability (often based on the frequency table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3400b-f086-4b7b-b3ed-83fd458f9214",
   "metadata": {},
   "source": [
    "### Entropy ###\n",
    "The Entropy can explicitely be written:\n",
    "$$ H(x)=\\sum_{i=2}^n P(x_i)I(x_i)= -\\sum_{i=1}^n P(x_i) log_b P(x_i) $$\n",
    "Where b is the base of the algorithm used. Common values of b are 2, Euler's number e, and 10.\n",
    "<b>Which should i use?</b>\n",
    "<ul><li>They tend to generate similar tree.</li>\n",
    "<li>Gini tends to be faster to compute.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a63d8d-0bc1-490e-ab8e-a19152cc7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(p):\n",
    "    return p*(1-p)+(1-p)*(1-( 1-p))\n",
    "def entropy(p):\n",
    "    return -p*np.log2(p)-(1-p)*np.log2(1-p)\n",
    "def error(p):\n",
    "    return 1-np.max([p,1-p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338fbb78-8757-447b-a849-e59ab9164566",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.arange(0,1,0.01)\n",
    "ent=[entropy(p) if p!=0 else None for p in x]\n",
    "sc_ent=[e*0.5 if e else None for e in ent]\n",
    "err=[error(i) for i in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef70ab8-e3b5-4a69-9178-b3ce07317903",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,6))\n",
    "ax= plt.subplot(111)\n",
    "for i, lab, Ls, c, in zip ([ent,sc_ent,gini(x),err], ['Entropy', 'Entropy Scaled', 'Gini Impurity',\n",
    "                                             'Misclassification error'],\n",
    "                          ['-','-','--','-'],['black', 'orange','red', 'cyan']):\n",
    "    line=ax.plot(x, i, label=lab, linestyle=Ls, lw=2, color=c)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5,1.15),ncol=3, fancybox=True, shadow=False)\n",
    "ax.axhline(y=0.5, linewidth=1, color='k', linestyle='--')\n",
    "ax.axhline(y=1, linewidth=1, color='k', linestyle='--')\n",
    "plt.ylim([0,1.15])\n",
    "plt.xlabel('p (i=1)')\n",
    "plt.ylabel('Impurity Index')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543be33d-5e94-4cbe-9927-a44daa1d31d6",
   "metadata": {},
   "source": [
    "# III. Regression, Regularization and Over fitting #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9906ead-edd8-4032-a229-1fb470f3976a",
   "metadata": {},
   "source": [
    "## 1) Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42365408-fc84-464f-bc4b-6c0bec3f9ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Create random Dataset:\n",
    "rng=np.random.RandomState(1)\n",
    "X=np.sort(5*rng.rand(80,1),axis=0)\n",
    "Y=np.sin(X).ravel()\n",
    "Y[::5]+=3*(0.5-rng.rand(16))\n",
    "#Fit regression model\n",
    "regr_1=DecisionTreeRegressor(max_depth=2)\n",
    "regr_2=DecisionTreeRegressor(max_depth=5, min_samples_leaf=10) #regularization\n",
    "regr_1.fit(X,Y)\n",
    "regr_2.fit(X,Y)\n",
    "#predict:\n",
    "X_test=np.arange(0.0, 5.0,0.01)[:,np.newaxis]\n",
    "Y_1=regr_1.predict(X_test)\n",
    "Y_2=regr_2.predict(X_test)\n",
    "regr_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edcca4f-b351-40d2-931a-af65bf1fae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X,Y, s=20,edgecolor='k', c='darkorange', label='data')\n",
    "plt.plot(X_test,Y_1, color='cornflowerblue', label='max_depth=2', linewidth=2 )\n",
    "plt.plot(X_test,Y_2, color='yellowgreen', label='max_depth=5', linewidth=2 )\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3bb17-83eb-4439-a7fa-86f21b1ca74b",
   "metadata": {},
   "source": [
    "## 2) Over fitting ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ead5d2-220e-40c3-8049-294c2e090a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "Iris=pd.read_csv(r'C:\\Users\\minam\\Dev py\\Coursera\\Machine Learning_Anthony Ng/Data/Iris.csv')\n",
    "Iris\n",
    "X=Iris.iloc[:, 1:5]\n",
    "Y=Iris.iloc[:, 5:6]\n",
    "X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76b290-fdf9-4cb4-b71f-a31c85cf4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=tree.DecisionTreeClassifier(random_state=42)\n",
    "clf=clf.fit(X,Y)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3664797-3a9a-455a-a288-8f5b54fb3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "fn='SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm','PetalWidthCm'\n",
    "dot_data=tree.export_graphviz(clf, out_file=None,feature_names=fn ,class_names='Species',rounded=True, filled=True )\n",
    "graph=graphviz.Source(dot_data)\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4f6a2-916c-4618-9109-6712d855d924",
   "metadata": {},
   "source": [
    "# IV. Modelling End-to-End with Decision Tree #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573766a2-73ed-4245-b627-7b029d26b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_data, Y_data= make_moons(n_samples=1000, noise=0.5, random_state=42)\n",
    "Cla1=tree.DecisionTreeClassifier(random_state=42)\n",
    "Cla2=tree.DecisionTreeClassifier(min_samples_leaf=10,random_state=42)\n",
    "X_train,X_test, Y_train,Y_test =train_test_split(X_data,Y_data,test_size= 0.1, random_state=42)\n",
    "X_data,Y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d9a5a-bd99-4c34-b62b-39dc590e6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'min_samples_leaf': list(range(5,20))}\n",
    "Grid_search_cv=GridSearchCV(tree.DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1)\n",
    "Grid_search_cv.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f803fe-3a45-488e-ad33-f96eb5f0a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid_search_cv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7841bd-4adb-4b54-8c68-9090623228fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y_pred=Grid_search_cv.predict(X_test)\n",
    "accuracy_score(Y_test,Y_pred )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1b753-df3b-4a8f-9cab-ea3ef56591d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cla1.fit(X_train, Y_train)\n",
    "Y_pred=Cla1.predict(X_test)\n",
    "accuracy_score(Y_test,Y_pred )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e506ea-7f41-4862-a690-cd8667ca6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cla1.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5a025-1ef4-47e3-b316-9b96c93cb7c3",
   "metadata": {},
   "source": [
    "### tips on practical use: ###\n",
    "<ul>\n",
    "<li>Decision trees tend to overfit on data with a large number of features. Check ratio of samples to number of features.</li>\n",
    "<li>Consider performing dimensionality reduction (PCA, ICA, or feature selection) beforehand.\n",
    "<li>Visualise your tree as you are training by using the export function. use max_depth=3 as an initial tree depth.\n",
    "<li>Use max_depth to control the size of the tree to prevent overfitting.\n",
    "<li>Tune min_samples_split or min_samples_leaf to control the number of samples at a leaf node.\n",
    "<li>Balance your Dataset before training to prevent the Tree from being biased toward the classes that are dominant:\n",
    "<ul>\n",
    "    <li>By sampling an equal number of samples of each class </li>\n",
    "    <li>By normalizing the sum of the samples weights (sample_weight) for each class to the same value\n",
    "    \n",
    "</ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094bd465-821f-472f-b580-1d80b5b12c7a",
   "metadata": {},
   "source": [
    "# V. Project HR #\n",
    "## 1) EDA ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2995b8-3a4a-499b-97cf-8ee59b03a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR=pd.read_csv(r'Data/HR-Employee-Attrition.csv')\n",
    "HR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb84643-5ee7-4411-8646-109fe741aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HR.shape\n",
    "HR.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca674149-517d-46a9-8551-6ca6f83efba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HR.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e1e64-e4f9-47a3-ac2c-a71a5fdcabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8209db-a0e7-4fd1-b1a8-fd1823906759",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format='{:,.2f}'.format\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.width',1000)\n",
    "HR.describe() #automatically ignore the categorical data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482aaf0-9882-477b-b2e9-37c1b3fee703",
   "metadata": {},
   "source": [
    "observations deduced from describe():\n",
    "<ul>\n",
    "<li><b>EmplyeeCount:</b>All values are 1, little information, can drop column. </li>\n",
    "<li><b>EmplyeeNumber:</b>Sequential count.little information, can drop column.</li>\n",
    "<li><b>StandardHours:</b>All values are 80, little information, can drop column.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fe09b9-b95d-4f88-b741-b36c3e978d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col=list(HR.describe().columns)\n",
    "categorical_col=list(set(HR.columns).difference(num_col))\n",
    "remove_list=['EmplyeeCount','EmplyeeNumber','StandardHours']\n",
    "col_numerical=[e for e in num_col if e not in remove_list]\n",
    "categorical_col, col_numerical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8b9f4-96a3-49be-ba4c-9685cd640708",
   "metadata": {},
   "source": [
    "### 2nd method ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b05710-04f4-4479-834b-e4e08af75261",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col=[]\n",
    "for k,v in HR.iteritems():\n",
    "    if v.dtype == 'object':\n",
    "        categorical_col.append(k)\n",
    "categorical_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea188ea-3609-4be9-abcf-7bb60218677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR.info()\n",
    "print(len(num_col))\n",
    "print(len(col_numerical))\n",
    "print(len(categorical_col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d2087-b1b6-417f-9ee2-b9dc872ae9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR[col_numerical].corr()\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(HR[col_numerical].corr(), annot=True, fmt='.2f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b6eae-6e79-4953-a9da-ac3640392b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "#mask for upper triangle\n",
    "mask=np.zeros_like(HR[col_numerical].corr(), dtype=bool)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "#Generate custom diverging colormap\n",
    "cmap=sns.diverging_palette(220,10,as_cmap=True)\n",
    "#Heatmap with mask with correct aspect ratio\n",
    "sns.heatmap(HR[col_numerical].corr(), mask=mask, cmap=cmap, vmax=0.3, \n",
    "            center=0, square=True, linewidths=0.5, cbar_kws={'shrink':0.5})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240769d9-f037-49c4-953c-3bc839cc026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "#mask for upper triangle\n",
    "mask=np.zeros_like(HR[col_numerical].corr(), dtype=bool)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "#Generate custom diverging colormap\n",
    "cmap=sns.light_palette((210,90,60), input='husl')\n",
    "#Heatmap with mask with correct aspect ratio\n",
    "sns.heatmap(HR[col_numerical].corr(), mask=mask, cmap=cmap, annot=True, fmt='.2f')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c5439-0b75-4338-87dc-50aa2eb5cc96",
   "metadata": {},
   "source": [
    "Correlation > 0.7 is closely correlated. We'll use 0.7 as guide into investigation:\n",
    "<ul>\n",
    "<li>Monthly income and Job level</li>\n",
    "<li>Total working years and Job level  </li>\n",
    "<li>Total working years and Monthly income   </li> \n",
    "<li>Performance rating and Percent salary hike </li>    \n",
    "<li>Years in current role and Years at company </li>   \n",
    "<li>Years with current manager and Years at company </li>\n",
    "<li>Years with current manager and Years in current role </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040ae56-5ef9-4ba6-9f13-d6d4c5f9b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR['Attrition'].unique()\n",
    "Attrition_num={'Yes':1, 'No':0}\n",
    "categorical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de3d5f-06c6-4060-b597-1feb1e3f525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR['Attrition_num']=HR['Attrition'].map(Attrition_num)\n",
    "HR['Attrition_num']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f206c0-9367-4a8a-9809-6cd3546b05c4",
   "metadata": {},
   "source": [
    "Use get_dummies or labelEncoder. <br>\n",
    "Point to note:\n",
    "<ul>\n",
    "<li>Perform one hot encoding before train-test-split. This is fine as you are just transforming the data.There is no leakage here.</li>\n",
    "<li>Perform data processing after train-test split because standardisation learn from the data by calculating mean, std etc...</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f400baa-6692-4ce9-8eb2-98d752cc086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col.remove('Attrition')\n",
    "DF_categ=pd.get_dummies(HR[categorical_col])\n",
    "DF_categ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f60278-e1c2-46e9-a3c2-d486ec4fb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.concat([HR[col_numerical], DF_categ], axis=1)\n",
    "Y=HR['Attrition_num']\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6bfaab-80dd-4391-a748-09947e52e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts()\n",
    "X.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7101df5-8f75-4b24-a16d-4ce313294bb4",
   "metadata": {},
   "source": [
    "## 2) Decision Tree Classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a423b-0a6d-43d1-a116-208f55f94306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train,X_test, Y_train,Y_test=train_test_split(X, Y, test_size=0.2 )\n",
    "T=tree.DecisionTreeClassifier(random_state=42)\n",
    "clf=T.fit(X_train, Y_train)\n",
    "clf\n",
    "X_train.shape, Y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b0123-4298-4e8c-a369-f80f14398013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "score1=accuracy_score(Y_train, clf.predict(X_train))\n",
    "score2=classification_report(Y_train, clf.predict(X_train))\n",
    "score3=confusion_matrix(Y_train, clf.predict(X_train))\n",
    "print(f'Accuracy= {score1:.3f},\\n Classification :\\n{score2}, \\n Confusion Matrix:\\n{score3}\\n')\n",
    "#:.3f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880bbeb-c2cb-4f41-98bd-fbef91dea711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
